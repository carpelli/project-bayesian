{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49276642",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf55a4",
   "metadata": {},
   "source": [
    "This Notebook treats 4 distinct classification problems using differnt Naive Bayes Classification models. We are going to use Bayesian, Gaussian, Multinomial and Complement Naive Bayes. We use the Scikit Library Naive Bayes that can be seen in: https://scikit-learn.org/stable/modules/naive_bayes.html. This library uses MLE frequentist estimators but also introduces smoothing and binning techniques to be able to treat a wider range of data for each of the models, this allows the treatment of discrete data as continous and continous as discrete. Everything can be found in the documentation in the link given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d66dd1",
   "metadata": {},
   "source": [
    "## Bayes Using SciKit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89948433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f68e3",
   "metadata": {},
   "source": [
    "## Checking mail spam:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555cd5f",
   "metadata": {},
   "source": [
    "Given an e-mail message, determine wheather such message is Spam or Ham:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b97950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/spam.csv\", encoding= 'latin-1')\n",
    "data = data[[\"class\", \"message\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc3202d",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67dff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[\"message\"])\n",
    "y = np.array(data[\"class\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780093e",
   "metadata": {},
   "source": [
    "### Using Bernoulli Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6c024c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97847533632287\n",
      "0.9876598608929773\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB(binarize=0.0)\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n",
    "print(model.score(xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2424878e",
   "metadata": {},
   "source": [
    "### Using Gaussian Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c85c5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9004484304932735\n",
      "0.9497419789095805\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(xtrain.toarray(), ytrain)\n",
    "print(model.score(xtest.toarray(), ytest))\n",
    "print(model.score(xtrain.toarray(),ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21ce97",
   "metadata": {},
   "source": [
    "### Using Multinomial Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a62c33e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97847533632287\n",
      "0.9943908458604442\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n",
    "print(model.score(xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a8843",
   "metadata": {},
   "source": [
    "### Using Complement Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45f6de2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9641255605381166\n",
      "0.9856405654027373\n"
     ]
    }
   ],
   "source": [
    "model = ComplementNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n",
    "print(model.score(xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a162f8",
   "metadata": {},
   "source": [
    "## IMDB Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1ef3b",
   "metadata": {},
   "source": [
    "Given a Review of a Film from IMDB determine if such review is positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d138400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/IMDB_Dataset.csv')\n",
    "#https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bee5cd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4bf830",
   "metadata": {},
   "source": [
    "### Dataset Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "868bafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df[\"review\"])\n",
    "y = np.array(df[\"sentiment\"])\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f59df2",
   "metadata": {},
   "source": [
    "### Using Bernoulli Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "013acaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8532\n",
      "0.89815\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB(binarize=0.0)\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n",
    "print(model.score(xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1accc",
   "metadata": {},
   "source": [
    "### Using Gaussian Naive Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a846686a",
   "metadata": {},
   "source": [
    "It does not Work with Gaussian Naive Bayes, since the use of sparse matrices is not allowed when computing the Gaussian Naive Bayes, and the dataset is far too large to perform the calculations with a non-sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa3b08",
   "metadata": {},
   "source": [
    "### Using Multinomial Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "efddc754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8487\n",
      "0.891\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n",
    "print(model.score(xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0816f03c",
   "metadata": {},
   "source": [
    "### Using Complement Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b559993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8487\n",
      "0.89105\n"
     ]
    }
   ],
   "source": [
    "model = ComplementNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n",
    "print(model.score(xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365778cb",
   "metadata": {},
   "source": [
    "## Type of Raisin Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1b466cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Raisin_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48cc2f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87524</td>\n",
       "      <td>442.246011</td>\n",
       "      <td>253.291155</td>\n",
       "      <td>0.819738</td>\n",
       "      <td>90546</td>\n",
       "      <td>0.758651</td>\n",
       "      <td>1184.040</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75166</td>\n",
       "      <td>406.690687</td>\n",
       "      <td>243.032436</td>\n",
       "      <td>0.801805</td>\n",
       "      <td>78789</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>1121.786</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90856</td>\n",
       "      <td>442.267048</td>\n",
       "      <td>266.328318</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>93717</td>\n",
       "      <td>0.637613</td>\n",
       "      <td>1208.575</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45928</td>\n",
       "      <td>286.540559</td>\n",
       "      <td>208.760042</td>\n",
       "      <td>0.684989</td>\n",
       "      <td>47336</td>\n",
       "      <td>0.699599</td>\n",
       "      <td>844.162</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79408</td>\n",
       "      <td>352.190770</td>\n",
       "      <td>290.827533</td>\n",
       "      <td>0.564011</td>\n",
       "      <td>81463</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>1073.251</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>83248</td>\n",
       "      <td>430.077308</td>\n",
       "      <td>247.838695</td>\n",
       "      <td>0.817263</td>\n",
       "      <td>85839</td>\n",
       "      <td>0.668793</td>\n",
       "      <td>1129.072</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>87350</td>\n",
       "      <td>440.735698</td>\n",
       "      <td>259.293149</td>\n",
       "      <td>0.808629</td>\n",
       "      <td>90899</td>\n",
       "      <td>0.636476</td>\n",
       "      <td>1214.252</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>99657</td>\n",
       "      <td>431.706981</td>\n",
       "      <td>298.837323</td>\n",
       "      <td>0.721684</td>\n",
       "      <td>106264</td>\n",
       "      <td>0.741099</td>\n",
       "      <td>1292.828</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>93523</td>\n",
       "      <td>476.344094</td>\n",
       "      <td>254.176054</td>\n",
       "      <td>0.845739</td>\n",
       "      <td>97653</td>\n",
       "      <td>0.658798</td>\n",
       "      <td>1258.548</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>85609</td>\n",
       "      <td>512.081774</td>\n",
       "      <td>215.271976</td>\n",
       "      <td>0.907345</td>\n",
       "      <td>89197</td>\n",
       "      <td>0.632020</td>\n",
       "      <td>1272.862</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0    87524       442.246011       253.291155      0.819738       90546   \n",
       "1    75166       406.690687       243.032436      0.801805       78789   \n",
       "2    90856       442.267048       266.328318      0.798354       93717   \n",
       "3    45928       286.540559       208.760042      0.684989       47336   \n",
       "4    79408       352.190770       290.827533      0.564011       81463   \n",
       "..     ...              ...              ...           ...         ...   \n",
       "895  83248       430.077308       247.838695      0.817263       85839   \n",
       "896  87350       440.735698       259.293149      0.808629       90899   \n",
       "897  99657       431.706981       298.837323      0.721684      106264   \n",
       "898  93523       476.344094       254.176054      0.845739       97653   \n",
       "899  85609       512.081774       215.271976      0.907345       89197   \n",
       "\n",
       "       Extent  Perimeter    Class  \n",
       "0    0.758651   1184.040  Kecimen  \n",
       "1    0.684130   1121.786  Kecimen  \n",
       "2    0.637613   1208.575  Kecimen  \n",
       "3    0.699599    844.162  Kecimen  \n",
       "4    0.792772   1073.251  Kecimen  \n",
       "..        ...        ...      ...  \n",
       "895  0.668793   1129.072    Besni  \n",
       "896  0.636476   1214.252    Besni  \n",
       "897  0.741099   1292.828    Besni  \n",
       "898  0.658798   1258.548    Besni  \n",
       "899  0.632020   1272.862    Besni  \n",
       "\n",
       "[900 rows x 8 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761fbb1",
   "metadata": {},
   "source": [
    "### Dataset Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76133da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df.drop(\"Class\", axis=1))\n",
    "y = np.array(df[\"Class\"])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3124f",
   "metadata": {},
   "source": [
    "### Using Bernoulli Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a59665ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4777777777777778\n",
      "0.5055555555555555\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB(binarize=0.0)\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n",
    "print(model.score(xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a57c2",
   "metadata": {},
   "source": [
    "### Using Multinomial Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc1bd48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy is 0.8333333333333334\n",
      "The Testing accuracy is 0.7805555555555556\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(f\"The Training accuracy is {model.score(xtest, ytest)}\")\n",
    "print(f\"The Testing accuracy is {model.score(xtrain,ytrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831d343",
   "metadata": {},
   "source": [
    "### Using Gaussian Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7799a1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy is 0.8277777777777777\n",
      "The Testing accuracy is 0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(f\"The Training accuracy is {model.score(xtest, ytest)}\")\n",
    "print(f\"The Testing accuracy is {model.score(xtrain,ytrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a65688",
   "metadata": {},
   "source": [
    "### Using Complement  Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7c46dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy is 0.8333333333333334\n",
      "The Testing accuracy is 0.7805555555555556\n"
     ]
    }
   ],
   "source": [
    "model = ComplementNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(f\"The Training accuracy is {model.score(xtest, ytest)}\")\n",
    "print(f\"The Testing accuracy is {model.score(xtrain,ytrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd025c23",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "87888fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e1b785f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0      1            5.1           3.5            1.4           0.2   \n",
       "1      2            4.9           3.0            1.4           0.2   \n",
       "2      3            4.7           3.2            1.3           0.2   \n",
       "3      4            4.6           3.1            1.5           0.2   \n",
       "4      5            5.0           3.6            1.4           0.2   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "866f1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df.drop(\"Species\", axis=1))\n",
    "y = np.array(df[\"Species\"])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc48cf4",
   "metadata": {},
   "source": [
    "### Using Bernoulli Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0952558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.3416666666666667\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB(binarize=0.0)\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n",
    "print(model.score(xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8ca77",
   "metadata": {},
   "source": [
    "### Using Multinomial Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ba47922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy is 0.9333333333333333\n",
      "The Testing accuracy is 0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(f\"The Training accuracy is {model.score(xtest, ytest)}\")\n",
    "print(f\"The Testing accuracy is {model.score(xtrain,ytrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968cdf5",
   "metadata": {},
   "source": [
    "### Using Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce855105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy is 1.0\n",
      "The Testing accuracy is 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(f\"The Training accuracy is {model.score(xtest, ytest)}\")\n",
    "print(f\"The Testing accuracy is {model.score(xtrain,ytrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d17d1",
   "metadata": {},
   "source": [
    "### Using Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "624a1254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy is 0.7\n",
      "The Testing accuracy is 0.6583333333333333\n"
     ]
    }
   ],
   "source": [
    "model = ComplementNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(f\"The Training accuracy is {model.score(xtest, ytest)}\")\n",
    "print(f\"The Testing accuracy is {model.score(xtrain,ytrain)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
